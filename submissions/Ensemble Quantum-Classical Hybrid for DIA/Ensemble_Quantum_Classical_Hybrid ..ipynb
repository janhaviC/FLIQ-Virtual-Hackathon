{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt49aU7v-P1H",
        "outputId": "a3ae005c-2664-4684-a01a-a419ca488be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.41.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.47.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.15.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.41 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.41->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Downloading PennyLane-0.41.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 pennylane-0.41.1 pennylane-lightning-0.41.1 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane shap\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pennylane-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9S41yakIqv8",
        "outputId": "287853ac-f080-4220-f405-48c49aed14d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pennylane-lightning in /usr/local/lib/python3.11/dist-packages (0.41.1)\n",
            "Requirement already satisfied: pennylane>=0.41 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning) (0.41.1)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning) (0.3.29.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (1.15.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (3.4.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (0.16.0)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (1.8.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (0.13.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (0.7.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (5.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (4.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (24.2)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.11/dist-packages (from pennylane>=0.41->pennylane-lightning) (2.15.2)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane>=0.41->pennylane-lightning) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane>=0.41->pennylane-lightning) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane>=0.41->pennylane-lightning) (3.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane>=0.41->pennylane-lightning) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane>=0.41->pennylane-lightning) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane>=0.41->pennylane-lightning) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane>=0.41->pennylane-lightning) (2025.4.26)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane>=0.41->pennylane-lightning) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane>=0.41->pennylane-lightning) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import logging, random\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "import pennylane as qml\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "M5CuH5-9wmaT"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# **Operational Reliability**: Fix random seeds for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Set up basic logging for key events\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.info(\"Environment initialized with seed %d\", seed)\n",
        "\n",
        "# Log versions of key libraries for reproducibility tracking\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "import pennylane as qml\n",
        "print(f\"PennyLane version: {qml.version()}\")\n",
        "import shap\n",
        "print(f\"SHAP version: {shap.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uuo-DUvwzRZ",
        "outputId": "433ca73a-2a86-4773-e484-bc4e59718a7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "PennyLane version: 0.41.1\n",
            "SHAP version: 0.47.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# **Secure Data Handling**: (In production, consider encryption for sensitive data)\n",
        "# Load training and test datasets\n",
        "train_df = pd.read_csv(\"DIA_trainingset_RDKit_descriptors.csv\")\n",
        "test_df  = pd.read_csv(\"DIA_testset_RDKit_descriptors.csv\")\n",
        "\n",
        "# Separate features and labels; drop non-numeric identifiers\n",
        "X_train_full = train_df.drop(columns=[\"Label\", \"SMILES\"])\n",
        "y_train_full = train_df[\"Label\"].values  # binary labels (0 or 1)\n",
        "X_test_full  = test_df.drop(columns=[\"Label\", \"SMILES\"])\n",
        "y_test       = test_df[\"Label\"].values\n",
        "\n",
        "# Standardize features (fit on training, apply to all sets)\n",
        "scaler = StandardScaler()\n",
        "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
        "X_test_scaled       = scaler.transform(X_test_full)\n",
        "\n",
        "# Split training data into training and validation subsets\n",
        "X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(\n",
        "    X_train_full_scaled, y_train_full, test_size=0.15, stratify=y_train_full, random_state=seed\n",
        ")\n",
        "\n",
        "# Reduce dimensionality with PCA (keep top 5 components for quantum input)\n",
        "pca = PCA(n_components=5, random_state=seed)\n",
        "X_train = pca.fit_transform(X_train_scaled)\n",
        "X_val   = pca.transform(X_val_scaled)\n",
        "X_test  = pca.transform(X_test_scaled)\n",
        "\n",
        "print(\"Training samples:\", X_train.shape[0], \"| Features (PCA components):\", X_train.shape[1])\n",
        "print(\"Validation samples:\", X_val.shape[0], \"| Test samples:\", X_test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkPe9TvTx6xd",
        "outputId": "4733b48c-820d-4cf2-d297-306f61bb56b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 405 | Features (PCA components): 5\n",
            "Validation samples: 72 | Test samples: 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial"
      ],
      "metadata": {
        "id": "gdmjMj3yBAvp"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Hyperparameters & Device\n",
        "n_qubits   = 5\n",
        "n_layers   = 4\n",
        "batch_size = 32\n",
        "\n",
        "# Lightning simulator for fast analytic (adjoint) gradients\n",
        "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
        "\n",
        "# 2) QNode: per-sample, no batch magic\n",
        "@qml.qnode(dev, interface=\"torch\", diff_method=\"adjoint\")\n",
        "def qnode(inputs, weights, shift):\n",
        "    # inputs: tensor of shape (n_qubits,)\n",
        "    # weights: (n_layers, n_qubits, 3)\n",
        "    # shift:   (n_qubits,)\n",
        "    # 2a) Embed with trainable shift\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(inputs[i] + shift[i], wires=i)\n",
        "    # 2b) Variational layers\n",
        "    for layer in range(n_layers):\n",
        "        for wire in range(n_qubits):\n",
        "            a, b, c = weights[layer, wire]\n",
        "            qml.Rot(a, b, c, wires=wire)\n",
        "        # ring entanglement\n",
        "        for wire in range(n_qubits - 1):\n",
        "            qml.CNOT(wires=[wire, wire+1])\n",
        "        qml.CNOT(wires=[n_qubits-1, 0])\n",
        "    # 2c) Readout\n",
        "    return qml.expval(qml.PauliZ(0))"
      ],
      "metadata": {
        "id": "VyycS0U8Cak5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Wrap QNode into a TorchLayer\n",
        "weight_shapes = {\n",
        "    \"weights\": (n_layers, n_qubits, 3),\n",
        "    \"shift\":   (n_qubits,)\n",
        "}\n",
        "qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "\n",
        "# 4) Define HybridQNN with per-sample loop\n",
        "class HybridQNN(nn.Module):\n",
        "    def __init__(self, qlayer, n_qubits=5):\n",
        "        super().__init__()\n",
        "        self.qlayer   = qlayer\n",
        "        self.n_qubits = n_qubits\n",
        "        # Tiny classical head\n",
        "        self.head     = nn.Sequential(\n",
        "            nn.Linear(1, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, n_qubits) or (n_qubits,)\n",
        "        if x.ndim == 1:\n",
        "            x = x.unsqueeze(0)\n",
        "        bs, fq = x.shape\n",
        "        assert fq == self.n_qubits, f\"Expected {self.n_qubits} features, got {fq}\"\n",
        "        # Per-sample quantum pass\n",
        "        out = []\n",
        "        for i in range(bs):\n",
        "            qi = self.qlayer(x[i])        # returns scalar tensor\n",
        "            out.append(qi.squeeze())\n",
        "        qout = torch.stack(out)           # (batch_size,)\n",
        "        qout = qout.unsqueeze(1)          # (batch_size,1)\n",
        "        return self.head(qout).squeeze(1) # (batch_size,)"
      ],
      "metadata": {
        "id": "NcTcZ6XYBYGB"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Instantiate model, loss, optimizer\n",
        "model = HybridQNN(qlayer, n_qubits)\n",
        "neg, pos = (y_train == 0).sum(), (y_train == 1).sum()\n",
        "pos_weight = torch.tensor([neg/pos], dtype=torch.float32)\n",
        "criterion  = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer  = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "# 6) DataLoader (you’ve already created these)\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val_t   = torch.tensor(X_val,   dtype=torch.float32)\n",
        "y_val_t   = torch.tensor(y_val,   dtype=torch.float32)\n",
        "train_loader = DataLoader(\n",
        "    TensorDataset(X_train_t, y_train_t),\n",
        "    batch_size=batch_size, shuffle=True,\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n"
      ],
      "metadata": {
        "id": "ghVlMB2OE2qD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2) Function to train one QNN with a given random seed ---\n",
        "def train_qnn(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Re-instantiate quantum layer & model\n",
        "    qlayer_i = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
        "    model_i  = HybridQNN(qlayer_i, n_qubits)\n",
        "    optimizer = torch.optim.Adam(model_i.parameters(), lr=1e-2)\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # DataLoader (reshuffle per model)\n",
        "    train_loader_i = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(X_train_t, y_train_t),\n",
        "        batch_size=32, shuffle=True,\n",
        "        generator=torch.Generator().manual_seed(seed)\n",
        "    )\n",
        "\n",
        "    # Simple 15-epoch train (you can increase)\n",
        "    model_i.train()\n",
        "    for epoch in range(15):\n",
        "        for Xb, yb in train_loader_i:\n",
        "            optimizer.zero_grad()\n",
        "            logits = model_i(Xb)\n",
        "            loss   = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model_i\n",
        "\n",
        "# 4a) Fit Logistic Regression on your PCA features\n",
        "lr_model = LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=0)\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_probs = lr_model.predict_proba(X_test)[:, 1]   # positive‐class probs\n",
        "\n",
        "# 4b) Fit Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
        "# ────────────────────────────────────────────────────────────────\n",
        "\n",
        "# --- 5) Combine with classical baselines ---\n",
        "combined_probs = (\n",
        "    0.50 * ensemble_qnn_probs +\n",
        "    0.25 * lr_probs +\n",
        "    0.25 * rf_probs\n",
        ")\n",
        "\n",
        "# --- 6) Tune threshold on VALIDATION set using the same ensemble mixing ---\n",
        "# First compute validation probs for each component\n",
        "with torch.no_grad():\n",
        "    val_qnn_probs = np.mean(\n",
        "        [torch.sigmoid(m(X_val_t)).cpu().numpy() for m in qnn_models],\n",
        "        axis=0\n",
        "    )\n",
        "val_lr_probs = lr_model.predict_proba(X_val)[:,1]\n",
        "val_rf_probs = rf_model.predict_proba(X_val)[:,1]\n",
        "\n",
        "val_combined_probs = (\n",
        "    0.50 * val_qnn_probs +\n",
        "    0.25 * val_lr_probs +\n",
        "    0.25 * val_rf_probs\n",
        ")\n",
        "\n",
        "best_f1, best_thr = 0, 0.5\n",
        "for thr in np.linspace(0.1, 0.9, 17):\n",
        "    preds = (val_combined_probs >= thr).astype(int)\n",
        "    f1 = f1_score(y_val, preds)\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_thr = f1, thr\n",
        "\n",
        "print(f\"Chosen threshold = {best_thr:.2f} → Val F1 = {best_f1:.3f}\")\n",
        "\n",
        "# --- 7) Final evaluation on TEST set at best_thr ---\n",
        "final_preds = (combined_probs >= best_thr).astype(int)\n",
        "print(\"ENSEMBLE Test Metrics:\")\n",
        "print(\" Accuracy :\", accuracy_score(y_test, final_preds))\n",
        "print(\" Precision:\", precision_score(y_test, final_preds))\n",
        "print(\" Recall   :\", recall_score(y_test, final_preds))\n",
        "print(\" F1 Score :\", f1_score(y_test, final_preds))\n",
        "print(\" AUC      :\", roc_auc_score(y_test, combined_probs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hbAWZv3O6HX",
        "outputId": "729424d6-3a80-4191-b281-8763ca0eb574"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen threshold = 0.30 → Val F1 = 0.540\n",
            "ENSEMBLE Test Metrics:\n",
            " Accuracy : 0.6\n",
            " Precision: 0.37142857142857144\n",
            " Recall   : 0.8666666666666667\n",
            " F1 Score : 0.52\n",
            " AUC      : 0.6814814814814816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, test_preds)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# 2) Print the raw counts\n",
        "print(\"Confusion Matrix Counts:\")\n",
        "print(f\"  True Negatives : {tn}\")\n",
        "print(f\"  False Positives: {fp}\")\n",
        "print(f\"  False Negatives: {fn}\")\n",
        "print(f\"  True Positives : {tp}\")\n",
        "\n",
        "# 3) Display visually\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "disp.plot(ax=ax, cmap=\"Blues\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "m3bix_DbgXhu",
        "outputId": "3f9e53e9-3758-48e3-d4ca-08b1240f5b61"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix Counts:\n",
            "  True Negatives : 64\n",
            "  False Positives: 26\n",
            "  False Negatives: 21\n",
            "  True Positives : 9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Right after you load & split + PCA your NumPy arrays:\n",
        "print(\"X_train (np) shape:\", X_train.shape)\n",
        "print(\"y_train (np) shape:\", y_train.shape)\n",
        "print(\"X_val   (np) shape:\", X_val.shape)\n",
        "print(\"y_val   (np) shape:\", y_val.shape)\n",
        "print(\"X_test  (np) shape:\", X_test.shape)\n",
        "print(\"y_test  (np) shape:\", y_test.shape)\n",
        "\n",
        "# If anything looks off (e.g. zero rows, or features ≠ 5), go back and re-run your preprocessing cell.\n",
        "\n",
        "# Now, after converting to tensors but before DataLoader:\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "print(\"X_train_tensor shape:\", X_train_tensor.shape)\n",
        "print(\"y_train_tensor shape:\", y_train_tensor.shape)\n",
        "\n",
        "# And right after you create your DataLoader:\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "train_ds     = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, generator=torch.Generator().manual_seed(seed))\n",
        "print(\"Number of batches in train_loader:\", len(train_loader))\n",
        "print(\"Size of first batch Xb:\", next(iter(train_loader))[0].shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb0iP5ZJEP0W",
        "outputId": "0d77a8b7-f2d7-4cc8-92d7-073e40842096"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (np) shape: (405, 5)\n",
            "y_train (np) shape: (405,)\n",
            "X_val   (np) shape: (72, 5)\n",
            "y_val   (np) shape: (72,)\n",
            "X_test  (np) shape: (120, 5)\n",
            "y_test  (np) shape: (120,)\n",
            "X_train_tensor shape: torch.Size([405, 5])\n",
            "y_train_tensor shape: torch.Size([405])\n",
            "Number of batches in train_loader: 13\n",
            "Size of first batch Xb: torch.Size([32, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Extract molecular weights and define proxy groups\n",
        "molwts = test_df[\"MolWt\"].values\n",
        "median_molwt = np.median(molwts)\n",
        "heavy_mask = molwts > median_molwt    # Group A: “heavy” molecules\n",
        "light_mask = molwts <= median_molwt   # Group B: “light” molecules\n",
        "\n",
        "# 2) Compute positive‐prediction rates in each group\n",
        "#    ‘test_preds’ is your final ensemble’s binary predictions\n",
        "pos_rate_heavy = test_preds[heavy_mask].mean()\n",
        "pos_rate_light = test_preds[light_mask].mean()\n",
        "disparate_impact = min(pos_rate_heavy, pos_rate_light) / max(pos_rate_heavy, pos_rate_light)\n",
        "\n",
        "# 3) Compute misclassification (error) rates in each group\n",
        "y_test_array = np.array(y_test)  # ensure NumPy array for indexing\n",
        "error_rate_heavy = 1 - accuracy_score(y_test_array[heavy_mask], test_preds[heavy_mask])\n",
        "error_rate_light = 1 - accuracy_score(y_test_array[light_mask], test_preds[light_mask])\n",
        "\n",
        "# 4) Report results\n",
        "print(f\"Positive prediction rate – Heavy: {pos_rate_heavy:.3f}, Light: {pos_rate_light:.3f}\")\n",
        "print(f\"Disparate Impact Ratio (Heavy vs Light): {disparate_impact:.3f}\")\n",
        "print(f\"Error rate – Heavy group: {error_rate_heavy:.3f}, Light group: {error_rate_light:.3f}\")"
      ],
      "metadata": {
        "id": "fduO8ry90FtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62d987da-61bc-432c-cfff-03102ccde789"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive prediction rate – Heavy: 0.250, Light: 0.333\n",
            "Disparate Impact Ratio (Heavy vs Light): 0.750\n",
            "Error rate – Heavy group: 0.333, Light group: 0.450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure model is in eval mode\n",
        "model.eval()\n",
        "\n",
        "epsilons = [0.0, 0.05, 0.1, 0.2]\n",
        "print(\"\\nAdversarial FGSM Attack Evaluation:\")\n",
        "for eps in epsilons:\n",
        "    correct = 0\n",
        "    # Loop over each test sample\n",
        "    for i in range(len(X_test)):\n",
        "        # 1) Prepare input and label\n",
        "        x_orig = torch.tensor(X_test[i], dtype=torch.float32).unsqueeze(0)  # (1, n_qubits)\n",
        "        y_true = y_test[i]\n",
        "\n",
        "        # 2) Compute gradient w.rt input\n",
        "        x_adv = x_orig.clone().detach().requires_grad_(True)\n",
        "        logit = model(x_adv)                                             # forward pass\n",
        "        loss  = criterion(logit, torch.tensor([y_true], dtype=torch.float32))\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        grad_sign = x_adv.grad.sign()                                     # FGSM direction\n",
        "\n",
        "        # 3) Create adversarial example\n",
        "        x_perturbed = x_orig + eps * grad_sign\n",
        "\n",
        "        # 4) Evaluate perturbed example\n",
        "        with torch.no_grad():\n",
        "            adv_prob = torch.sigmoid(model(x_perturbed)).item()\n",
        "        adv_pred = 1 if adv_prob >= 0.5 else 0\n",
        "\n",
        "        # 5) Check correctness\n",
        "        if adv_pred == int(y_true):\n",
        "            correct += 1\n",
        "\n",
        "    adv_acc = correct / len(X_test)\n",
        "    print(f\"  Epsilon = {eps:.2f} -> Adversarial Accuracy = {adv_acc:.3f}\")"
      ],
      "metadata": {
        "id": "qGNi9Vz10Ia4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d624058-3324-4695-b0b1-8271b008db6d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Adversarial FGSM Attack Evaluation:\n",
            "  Epsilon = 0.00 -> Adversarial Accuracy = 0.600\n",
            "  Epsilon = 0.05 -> Adversarial Accuracy = 0.575\n",
            "  Epsilon = 0.10 -> Adversarial Accuracy = 0.533\n",
            "  Epsilon = 0.20 -> Adversarial Accuracy = 0.458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# 1) Save QNN weights (three models)\n",
        "for idx, model in enumerate(qnn_models):\n",
        "    torch.save(model.state_dict(), f\"qnn_model_{idx}.pth\")\n",
        "\n",
        "# 2) Save classical models (scaler, PCA, LR, RF)\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(pca,    \"pca.pkl\")\n",
        "joblib.dump(lr_model, \"logistic_model.joblib\")\n",
        "joblib.dump(rf_model, \"rf_model.joblib\")\n",
        "\n",
        "print(\"All models and preprocessors saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDN5aDV1jWDb",
        "outputId": "2bbf9d72-9211-49d6-e6b9-7bfa64c671fa"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All models and preprocessors saved.\n"
          ]
        }
      ]
    }
  ]
}