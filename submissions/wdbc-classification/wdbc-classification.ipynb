{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epPc3aiKLj1r",
        "outputId": "0887ce35-9764-4466-e911-9e313a221e3c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.41.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.15.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.41 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.41->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.4.26)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading PennyLane-0.41.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 pennylane-0.41.1 pennylane-lightning-0.41.1 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n",
            "Requirement already satisfied: pennylane in /usr/local/lib/python3.11/dist-packages (0.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.15.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.16.0)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.7.1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Requirement already satisfied: pennylane-lightning>=0.41 in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Requirement already satisfied: diastatic-malt in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.15.2)\n",
            "Requirement already satisfied: scipy-openblas32>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from pennylane-lightning>=0.41->pennylane) (0.3.29.0.0)\n",
            "Requirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.4.26)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Collecting qiskit\n",
            "  Downloading qiskit-2.0.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.16.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.15.3)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit) (0.3.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit) (2.9.0.post0)\n",
            "Collecting stevedore>=3.0.0 (from qiskit)\n",
            "  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit) (4.13.2)\n",
            "Collecting symengine<0.14,>=0.11 (from qiskit)\n",
            "  Downloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.17.0)\n",
            "Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n",
            "  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pbr>=2.0.0->stevedore>=3.0.0->qiskit) (75.2.0)\n",
            "Downloading qiskit-2.0.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading symengine-0.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: symengine, pbr, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, stevedore, nvidia-cusparse-cu12, nvidia-cudnn-cu12, qiskit, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pbr-6.1.1 qiskit-2.0.1 stevedore-5.4.1 symengine-0.13.0\n"
          ]
        }
      ],
      "source": [
        "! pip install pennylane\n",
        "! pip install pennylane\n",
        "! pip install qiskit torch numpy pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import pennylane as qml\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from qiskit import QuantumCircuit\n",
        "from qiskit.circuit import ParameterVector\n",
        "from qiskit.primitives import StatevectorEstimator\n",
        "from qiskit.quantum_info import SparsePauliOp\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "import pennylane as qml\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pennylane as qml\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1Eo1RCguRGg",
        "outputId": "0e8f7a41-8554-4916-9032-12c72e47f6db"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.5.2 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_dataset_name = \"wdbc_train\"\n",
        "x_val_dataset_name = \"wdbc_val\"\n",
        "x_test_dataset_name = \"wdbc_test\"\n",
        "\n",
        "model_name = \"wdbc_model\""
      ],
      "metadata": {
        "id": "kJcPjnFc0Gxp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataSet Creation\n",
        "\n",
        "Execute the below sections only if we want to create a fresh dataset. We already have datsets snaphots with us so we can directly use that."
      ],
      "metadata": {
        "id": "sVCUW_BAuDSj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFbGxdNZrlEF",
        "outputId": "d7b45050-6506-43fc-9e07-3bc4f017a501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-17 21:17:25--  https://raw.githubusercontent.com/Meta-user-byte/FLIQ/refs/heads/main/Datasets/breast%2Bcancer%2Bwisconsin%2Bdiagnostic/wdbc.data\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 124103 (121K) [text/plain]\n",
            "Saving to: ‘wdbc.data.4’\n",
            "\n",
            "\rwdbc.data.4           0%[                    ]       0  --.-KB/s               \rwdbc.data.4         100%[===================>] 121.19K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-05-17 21:17:25 (5.61 MB/s) - ‘wdbc.data.4’ saved [124103/124103]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://raw.githubusercontent.com/Meta-user-byte/FLIQ/refs/heads/main/Datasets/breast%2Bcancer%2Bwisconsin%2Bdiagnostic/wdbc.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_7R9iWhLrvHV"
      },
      "outputs": [],
      "source": [
        "\n",
        "def data_reader(filepath):\n",
        "    wdbc_columns = [\n",
        "    'id', 'diagnosis',\n",
        "    'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean',\n",
        "    'compactness_mean', 'concavity_mean', 'concave_points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
        "    'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
        "    'compactness_se', 'concavity_se', 'concave_points_se', 'symmetry_se', 'fractal_dimension_se',\n",
        "    'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
        "    'compactness_worst', 'concavity_worst', 'concave_points_worst', 'symmetry_worst', 'fractal_dimension_worst'\n",
        "    ]\n",
        "    # Detect delimiter\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        sample = f.read(2048)\n",
        "        sniffer = csv.Sniffer()\n",
        "        dialect = sniffer.sniff(sample)\n",
        "        delimiter = dialect.delimiter\n",
        "        df = pd.read_csv(filepath, delimiter=\",\", names=wdbc_columns)\n",
        "        return df\n",
        "\n",
        "\n",
        "def load_wdbc():\n",
        "  df = data_reader(\"wdbc.data\")\n",
        "  df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})\n",
        "  train_full = df.sample(frac=0.7)\n",
        "  test_full = df[~df.index.isin(train_full.index)]\n",
        "  X_train_full = train_full.drop(columns=['diagnosis']).values.astype(np.float32)\n",
        "  y_train_full = train_full['diagnosis'].values.astype(np.float32).reshape(-1, 1)\n",
        "  X_test_full = test_full.drop(columns=['diagnosis']).values.astype(np.float32)\n",
        "  y_test_full = test_full['diagnosis'].values.astype(np.float32).reshape(-1, 1)\n",
        "  return X_train_full, y_train_full, X_test_full, y_test_full\n",
        "\n",
        "#Drop the ID column\n",
        "seed = 42\n",
        "X_train_full, y_train_full, X_test_full, y_test = load_wdbc()\n",
        "\n",
        "\n",
        "# Standardize features (fit on training data, apply to train/val/test)\n",
        "scaler = StandardScaler()\n",
        "X_train_full_scaled = scaler.fit_transform(X_train_full)\n",
        "X_test_scaled = scaler.transform(X_test_full)\n",
        "\n",
        "# Split training data into train and validation subsets\n",
        "X_train_scaled, X_val_scaled, y_train, y_val = train_test_split(\n",
        "    X_train_full_scaled, y_train_full, test_size=0.15, stratify=y_train_full, random_state=seed\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "#Convert to torch tensors\n",
        "X_train = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "Y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "\n",
        "X_val = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
        "Y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "\n",
        "X_test = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "Y_test = torch.tensor(y_test, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading\n",
        "\n",
        "Load snapshot data for training, validation and testing"
      ],
      "metadata": {
        "id": "-LyEiYrlvR28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = torch.load(f\"{x_train_dataset_name}.pt\")\n",
        "Y_train = torch.load(f\"{x_train_dataset_name}_label.pt\")\n",
        "\n",
        "X_val = torch.load(f\"{x_val_dataset_name}.pt\")\n",
        "Y_val = torch.load(f\"{x_val_dataset_name}_label.pt\")\n",
        "\n",
        "X_test = torch.load(f\"{x_test_dataset_name}.pt\")\n",
        "Y_test = torch.load(f\"{x_test_dataset_name}_label.pt\")"
      ],
      "metadata": {
        "id": "gi7WVRD4vcz0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation\n",
        "\n",
        "Below we will design the model."
      ],
      "metadata": {
        "id": "FKTW2izRwUyP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k7nfwWSEU3fj"
      },
      "outputs": [],
      "source": [
        "def get_pos_weight(labels):\n",
        "    \"\"\"\n",
        "    Calculates the positive class weight based on the distribution of labels.\n",
        "\n",
        "    Args:\n",
        "        labels (torch.Tensor): A 1D tensor of labels (0 and 1).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor containing the positive class weight.\n",
        "    \"\"\"\n",
        "    positive_count = torch.sum(labels)\n",
        "    negative_count = len(labels) - positive_count\n",
        "    if positive_count > 0:\n",
        "        pos_weight = negative_count / positive_count\n",
        "    else:\n",
        "        pos_weight = torch.tensor(1.0)  # Avoid division by zero\n",
        "    return pos_weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k0wnUmBar2IR"
      },
      "outputs": [],
      "source": [
        "# 1. Classical Feature Processing Network\n",
        "class ClassicalFeatureExtractor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.LeakyReLU(0.01) #nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 2. Quantum Feature Map (Variational Quantum Circuit)\n",
        "n_qubits = 10  # Reduced number of features after classical processing\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def quantum_feature_map(inputs, weights, random_weights):\n",
        "    # Angle embedding of the classical features\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
        "\n",
        "\n",
        "    qml.templates.RandomLayers(random_weights, wires=range(n_qubits))\n",
        "    qml.templates.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "\n",
        "    return qml.expval(qml.PauliZ(0))\n",
        "\n",
        "# 3. Hybrid Model\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, input_size, classical_hidden, quantum_out_size, quantum_weights_shape):\n",
        "        super().__init__()\n",
        "        self.classical_extractor = ClassicalFeatureExtractor(input_size, classical_hidden, quantum_out_size)\n",
        "        self.quantum_weights = nn.Parameter(torch.randn(strongly_entangling_shape))\n",
        "        self.quantum_random_weights = nn.Parameter(torch.randn(random_shape))\n",
        "        self.classical_classifier = nn.Linear(1, 1).float() # Binary classification output (single neuron)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Classical feature extraction\n",
        "        processed_features = self.classical_extractor(x)\n",
        "\n",
        "        # Quantum feature map\n",
        "        quantum_output = torch.stack([quantum_feature_map(feature, self.quantum_weights, self.quantum_random_weights) for feature in processed_features])\n",
        "\n",
        "        # Classical classification layer\n",
        "        output = self.classical_classifier(quantum_output.unsqueeze(1).float())\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_size = len(X_train[0,:])\n",
        "classical_hidden = 20\n",
        "quantum_out_size = n_qubits\n",
        "layers = 3\n",
        "quantum_weights_shape = (layers, n_qubits) # Example: 2 layers of RY rotations\n",
        "strongly_entangling_shape = qml.StronglyEntanglingLayers.shape(layers, n_qubits)\n",
        "random_shape = qml.RandomLayers.shape(layers, n_qubits)\n",
        "model = HybridModel(input_size, classical_hidden, quantum_out_size, strongly_entangling_shape)\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=get_pos_weight(Y_train))\n"
      ],
      "metadata": {
        "id": "7fFtPhYmxBfn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "Run section to train the model"
      ],
      "metadata": {
        "id": "hnAXWyN-2qgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Training loop with gradient clipping and scheduler\n",
        "num_epochs = 50\n",
        "optimizer = torch.optim.Adam(\n",
        "    model.parameters(), lr=1e-3, weight_decay=1e-4\n",
        ")\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.5, patience=5, min_lr=1e-5, verbose=True\n",
        ")\n",
        "# 3) DataLoader for batching\n",
        "\n",
        "train_ds = TensorDataset(X_train, Y_train)\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch_X)\n",
        "        #print(batch_y, logits)\n",
        "        loss   = criterion(logits, batch_y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * batch_X.shape[0]\n",
        "    avg_loss = total_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_logits = model(X_val)\n",
        "        val_loss   = criterion(val_logits, Y_val).item()\n",
        "        val_preds  = (torch.sigmoid(val_logits) >= 0.05).float()\n",
        "        val_acc    = (val_preds == Y_val).float().mean().item()\n",
        "\n",
        "    print(f\"Epoch {epoch:2d} | Train loss {avg_loss:.4f} | Val loss {val_loss:.4f} | Val acc {val_acc:.3f}\")\n",
        "    scheduler.step(val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_Kfn6sPxTmZ",
        "outputId": "a6ad06f3-6ede-4499-da58-578d346a7dc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 | Train loss 0.8925 | Val loss 0.8902 | Val acc 0.383\n",
            "Epoch  2 | Train loss 0.8826 | Val loss 0.8825 | Val acc 0.383\n",
            "Epoch  3 | Train loss 0.8726 | Val loss 0.8730 | Val acc 0.383\n",
            "Epoch  4 | Train loss 0.8606 | Val loss 0.8624 | Val acc 0.383\n",
            "Epoch  5 | Train loss 0.8485 | Val loss 0.8507 | Val acc 0.383\n",
            "Epoch  6 | Train loss 0.8359 | Val loss 0.8395 | Val acc 0.383\n",
            "Epoch  7 | Train loss 0.8234 | Val loss 0.8277 | Val acc 0.383\n",
            "Epoch  8 | Train loss 0.8102 | Val loss 0.8144 | Val acc 0.383\n",
            "Epoch  9 | Train loss 0.7964 | Val loss 0.8017 | Val acc 0.383\n",
            "Epoch 10 | Train loss 0.7825 | Val loss 0.7886 | Val acc 0.383\n",
            "Epoch 11 | Train loss 0.7688 | Val loss 0.7756 | Val acc 0.383\n",
            "Epoch 12 | Train loss 0.7549 | Val loss 0.7634 | Val acc 0.383\n",
            "Epoch 13 | Train loss 0.7408 | Val loss 0.7510 | Val acc 0.383\n",
            "Epoch 14 | Train loss 0.7262 | Val loss 0.7366 | Val acc 0.383\n",
            "Epoch 15 | Train loss 0.7108 | Val loss 0.7213 | Val acc 0.383\n",
            "Epoch 16 | Train loss 0.6938 | Val loss 0.7078 | Val acc 0.383\n",
            "Epoch 17 | Train loss 0.6760 | Val loss 0.6891 | Val acc 0.383\n",
            "Epoch 18 | Train loss 0.6555 | Val loss 0.6702 | Val acc 0.383\n",
            "Epoch 19 | Train loss 0.6349 | Val loss 0.6520 | Val acc 0.383\n",
            "Epoch 20 | Train loss 0.6148 | Val loss 0.6356 | Val acc 0.383\n",
            "Epoch 21 | Train loss 0.5963 | Val loss 0.6192 | Val acc 0.383\n",
            "Epoch 22 | Train loss 0.5799 | Val loss 0.6072 | Val acc 0.383\n",
            "Epoch 23 | Train loss 0.5640 | Val loss 0.5936 | Val acc 0.383\n",
            "Epoch 24 | Train loss 0.5496 | Val loss 0.5808 | Val acc 0.383\n",
            "Epoch 25 | Train loss 0.5359 | Val loss 0.5722 | Val acc 0.383\n",
            "Epoch 26 | Train loss 0.5244 | Val loss 0.5631 | Val acc 0.383\n",
            "Epoch 27 | Train loss 0.5120 | Val loss 0.5515 | Val acc 0.383\n",
            "Epoch 28 | Train loss 0.5013 | Val loss 0.5445 | Val acc 0.383\n",
            "Epoch 29 | Train loss 0.4913 | Val loss 0.5348 | Val acc 0.383\n",
            "Epoch 30 | Train loss 0.4809 | Val loss 0.5262 | Val acc 0.383\n",
            "Epoch 31 | Train loss 0.4711 | Val loss 0.5215 | Val acc 0.383\n",
            "Epoch 32 | Train loss 0.4617 | Val loss 0.5118 | Val acc 0.383\n",
            "Epoch 33 | Train loss 0.4531 | Val loss 0.5061 | Val acc 0.383\n",
            "Epoch 34 | Train loss 0.4447 | Val loss 0.4986 | Val acc 0.383\n",
            "Epoch 35 | Train loss 0.4367 | Val loss 0.4927 | Val acc 0.383\n",
            "Epoch 36 | Train loss 0.4291 | Val loss 0.4885 | Val acc 0.383\n",
            "Epoch 37 | Train loss 0.4209 | Val loss 0.4798 | Val acc 0.383\n",
            "Epoch 38 | Train loss 0.4126 | Val loss 0.4739 | Val acc 0.383\n",
            "Epoch 39 | Train loss 0.4057 | Val loss 0.4649 | Val acc 0.383\n",
            "Epoch 40 | Train loss 0.3985 | Val loss 0.4634 | Val acc 0.383\n",
            "Epoch 41 | Train loss 0.3907 | Val loss 0.4545 | Val acc 0.383\n",
            "Epoch 42 | Train loss 0.3839 | Val loss 0.4489 | Val acc 0.383\n",
            "Epoch 43 | Train loss 0.3773 | Val loss 0.4461 | Val acc 0.383\n",
            "Epoch 44 | Train loss 0.3713 | Val loss 0.4413 | Val acc 0.383\n",
            "Epoch 45 | Train loss 0.3654 | Val loss 0.4377 | Val acc 0.383\n",
            "Epoch 46 | Train loss 0.3601 | Val loss 0.4349 | Val acc 0.383\n",
            "Epoch 47 | Train loss 0.3549 | Val loss 0.4294 | Val acc 0.383\n",
            "Epoch 48 | Train loss 0.3506 | Val loss 0.4268 | Val acc 0.383\n",
            "Epoch 49 | Train loss 0.3453 | Val loss 0.4223 | Val acc 0.383\n",
            "Epoch 50 | Train loss 0.3413 | Val loss 0.4189 | Val acc 0.383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Saved Model\n",
        "\n",
        "If we want to load the pre trained model, we can execute this section."
      ],
      "metadata": {
        "id": "F4g_0c0Azuvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(f\"{model_name}.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtsad4tpz7AD",
        "outputId": "459a6432-10bb-48ac-fc6a-6ef004d33275"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [ Optional ] Save Model and dataset"
      ],
      "metadata": {
        "id": "jIXTjiExxtdY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BVMHLQ6PsCCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7893dc62-5ea9-4170-a70d-a848d56bc2c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to wdbc_model_2025-05-17 21:00:28.265181.pt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "curr_time = str(datetime.datetime.now())\n",
        "# Save the model's state dictionary\n",
        "model_name = f'wdbc_model_{curr_time}.pt'\n",
        "torch.save(model.state_dict(), model_name)\n",
        "print(f\"Model saved to {model_name}\")\n",
        "\n",
        "# Save the tensors\n",
        "torch.save(X_train, f'wdbc_train_{curr_time}.pt')\n",
        "torch.save(Y_train, f'wdbc_train_label_{curr_time}.pt')\n",
        "\n",
        "torch.save(X_val, f'wdbc_val_{curr_time}.pt')\n",
        "torch.save(Y_val, f'wdbc_val_label_{curr_time}.pt')\n",
        "\n",
        "torch.save(X_test, f'wdbc_test_{curr_time}.pt')\n",
        "torch.save(Y_test, f'wdbc_test_label{curr_time}.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "JIMx1PGHysap"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "QJSUA8Yg8CeU",
        "outputId": "827d3cad-36b5-48fa-afb8-046259e0668a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.4349\n",
            "Accuracy: 0.9708\n",
            "Precision: 0.9394\n",
            "Recall: 0.9841\n",
            "F1 Score: 0.9612\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "loss_function = criterion\n",
        "\n",
        "def evaluate(model, test_loader, loss_function):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation during evaluation\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)  # Get the raw output (logits)\n",
        "            loss = loss_function(outputs, labels.float())  # Calculate the loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            probabilities = torch.sigmoid(outputs)  # Apply sigmoid to get probabilities\n",
        "            predictions = (probabilities >= 0.5).long()  # Convert probabilities to predictions\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            cm = confusion_matrix(labels, predictions)\n",
        "            plt.figure(figsize=(6, 4))\n",
        "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "            plt.title(\"Prediction Confusion Matrix\")\n",
        "            plt.xlabel(\"Predicted\")\n",
        "            plt.ylabel(\"Actual\")\n",
        "            plt.show()\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    return avg_loss, all_predictions, all_labels\n",
        "\n",
        "\n",
        "avg_test_loss, test_predictions, test_labels = evaluate(model, [[X_test, Y_test]], loss_function)\n",
        "\n",
        "# Now we can use test_predictions and test_labels to calculate metrics:\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "precision = precision_score(test_labels, test_predictions)\n",
        "recall = recall_score(test_labels, test_predictions)\n",
        "f1 = f1_score(test_labels, test_predictions)\n",
        "\n",
        "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculates precision, recall, F1-score, and accuracy.\n",
        "\n",
        "    Args:\n",
        "        y_true (list or numpy.ndarray): True labels (0 and 1).\n",
        "        y_pred (list or numpy.ndarray): Predicted labels (0 and 1).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the calculated metrics.\n",
        "    \"\"\"\n",
        "    # Ensure inputs are numpy arrays for easier calculations\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # 1. Confusion Matrix Components\n",
        "    #    These are the raw counts we need.\n",
        "    true_positives  = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    false_positives = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    true_negatives  = np.sum((y_true == 0) & (y_pred == 0))\n",
        "    false_negatives = np.sum((y_true == 1) & (y_pred == 0))\n",
        "\n",
        "    # 2. Precision\n",
        "    #    - What proportion of positive predictions were *actually* positive?\n",
        "    #    - High precision means low false positive rate (Type I error).\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n",
        "\n",
        "    # 3. Recall (Sensitivity, True Positive Rate)\n",
        "    #    - What proportion of *actual* positives did we correctly predict?\n",
        "    #    - High recall means low false negative rate (Type II error).\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n",
        "\n",
        "    # 4. F1-Score\n",
        "    #    - Harmonic mean of precision and recall.\n",
        "    #    - Balances precision and recall in a single metric.\n",
        "    #    - Useful when you want a trade-off between false positives and false negatives.\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    # 5. Accuracy\n",
        "    #    - Overall proportion of correct predictions.\n",
        "    accuracy = (true_positives + true_negatives) / len(y_true) if len(y_true) > 0 else 0.0\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1_score,\n",
        "        'accuracy': accuracy,\n",
        "        'true_positives': true_positives,\n",
        "        'false_positives': false_positives,\n",
        "        'true_negatives': true_negatives,\n",
        "        'false_negatives': false_negatives\n",
        "    }\n",
        "\n",
        "def print_metrics(metrics, problem_name=\"\"):\n",
        "    \"\"\"Prints the metrics in a user-friendly format.\n",
        "\n",
        "       Args:\n",
        "          metrics (dict): A dictionary of metrics\n",
        "          problem_name (str): Optional name of the problem.\n",
        "    \"\"\"\n",
        "    if (problem_name != \"\"):\n",
        "        print(f\"Results for {problem_name}:\")\n",
        "    print(f\"  Precision:     {metrics['precision']:.4f}\")\n",
        "    print(f\"  Recall:        {metrics['recall']:.4f}\")\n",
        "    print(f\"  F1 Score:      {metrics['f1_score']:.4f}\")\n",
        "    print(f\"  Accuracy:      {metrics['accuracy']:.4f}\")\n",
        "    print(f\"  True Positives:  {metrics['true_positives']:d}\")\n",
        "    print(f\"  False Positives: {metrics['false_positives']:d}\")\n",
        "    print(f\"  True Negatives:  {metrics['true_negatives']:d}\")\n",
        "    print(f\"  False Negatives: {metrics['false_negatives']:d}\")\n",
        "\n",
        "\n",
        "\n",
        "metrics = calculate_metrics(Y_test, test_predictions)\n",
        "\n",
        "# Print the metrics\n",
        "print_metrics(metrics, \"wdbc classification\")\n",
        "\n",
        "# Example of how the metrics relate to balancing errors:\n",
        "print(\"\\nBalancing False Positives and False Negatives:\")\n",
        "print(\"  - Precision focuses on minimizing False Positives (Type I error).\")\n",
        "print(\"  - Recall focuses on minimizing False Negatives (Type II error).\")\n",
        "print(\"  - F1 Score balances both Precision and Recall.\")\n",
        "print(\"  - Accuracy measures overall correctness but doesn't differentiate between\")\n",
        "print(\"    types of errors.\")"
      ],
      "metadata": {
        "id": "EVba76wxqr5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff697ce3-2281-49bb-9b5f-56b643bbd0d3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for Example Problem:\n",
            "  Precision:     0.9394\n",
            "  Recall:        0.9841\n",
            "  F1 Score:      0.9612\n",
            "  Accuracy:      0.9708\n",
            "  True Positives:  62\n",
            "  False Positives: 4\n",
            "  True Negatives:  104\n",
            "  False Negatives: 1\n",
            "\n",
            "Balancing False Positives and False Negatives:\n",
            "  - Precision focuses on minimizing False Positives (Type I error).\n",
            "  - Recall focuses on minimizing False Negatives (Type II error).\n",
            "  - F1 Score balances both Precision and Recall.\n",
            "  - Accuracy measures overall correctness but doesn't differentiate between\n",
            "    types of errors.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}